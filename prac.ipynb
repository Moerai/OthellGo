{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, copy\n",
    "import math, random\n",
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "from collections import deque\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "Variable = lambda *args, **kwargs: autograd.Variable(*args, **kwargs).cuda() if USE_CUDA else autograd.Variable(*args,\n",
    "                                                                                                                **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ReplayBuffer(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "\n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        state = np.expand_dims(state, 0)\n",
    "        state = np.expand_dims(state, 0)\n",
    "        next_state = np.expand_dims(next_state, 0)\n",
    "        next_state = np.expand_dims(next_state, 0)\n",
    "\n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        state, action, reward, next_state, done = zip(*random.sample(self.buffer, batch_size))\n",
    "        return np.concatenate(state), action, reward, np.concatenate(next_state), done\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "    \n",
    "    def change_last_done(self):\n",
    "        last = list(self.buffer[-1])\n",
    "        last[4] = True\n",
    "        self.buffer.pop()\n",
    "        self.buffer.append(last)\n",
    "        \n",
    "    def get_last(self):\n",
    "        return self.buffer[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CnnDQN(nn.Module):\n",
    "    def __init__(self, input_shape, num_actions):\n",
    "        super(CnnDQN, self).__init__()\n",
    "\n",
    "        self.input_shape = input_shape  # 8*8 state(observation) size\n",
    "        self.num_actions = num_actions  # 8*8 action size 난 똑같\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1),\n",
    "            # output는 6*6\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # fully connected = 그냥 신경망\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(32*6*6, 24),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(24, self.num_actions)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def feature_size(self):\n",
    "        return self.features(autograd.Variable(torch.zeros(32,1, *self.input_shape))).view(1, -1).size(1)\n",
    "\n",
    "    def act(self, state, epsilon, validlist):\n",
    "        if random.random() > epsilon:\n",
    "            state = np.expand_dims(np.float32(state), 0)\n",
    "            state = Variable(torch.FloatTensor(state).unsqueeze(0), volatile=True)\n",
    "            \n",
    "            q_value = self.forward(state)  # size 64의 linear [1,2,3,4]\n",
    "            # q_value에서 valid 한 것만 놔두기.\n",
    "            valid_q_value = []\n",
    "#             print(q_value)\n",
    "            for i in validlist:\n",
    "                idx = i[0]*8 + i[1]\n",
    "                valid_q_value.append(q_value[0, idx])\n",
    "                \n",
    "            # action = valid_q_value.max(1)[1].data[0]\n",
    "            val = np.max(valid_q_value)\n",
    "            val_idx = (q_value[0] == val).nonzero().item()\n",
    "            # 해당 인덱스의 좌표 찾기\n",
    "            x = int(val_idx//8)\n",
    "            y = int(val_idx % 8)\n",
    "            action = (x, y)\n",
    "\n",
    "        else:\n",
    "            random.shuffle(validlist)\n",
    "            (x, y) = validlist.pop()\n",
    "            x = int(x)\n",
    "            y = int(y)\n",
    "            action = (x, y)\n",
    "\n",
    "        return action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAwEAAAE/CAYAAAAe8M/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDNBCpA0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19711c92eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 번째 게임\n",
      "게임종료\n",
      "-1 -1 -1 -1 -1 -1 0 1  0\n",
      "1 -1 1 -1 -1 -1 -1 -1  1\n",
      "1 1 -1 1 -1 1 -1 -1  2\n",
      "1 -1 1 1 -1 -1 1 -1  3\n",
      "1 -1 1 1 -1 -1 1 -1  4\n",
      "1 -1 1 -1 1 -1 1 -1  5\n",
      "1 1 1 1 -1 1 1 -1  6\n",
      "1 1 1 1 1 1 1 -1  7\n",
      "0 1 2 3 4 5 6 7 \n",
      "\n",
      "Score Comp1: 32\n",
      "Score Comp2: 31\n",
      "\n",
      "8 번째 게임\n",
      "게임종료\n",
      "1 1 1 1 1 1 1 -1  0\n",
      "1 1 1 -1 1 1 -1 -1  1\n",
      "1 1 1 -1 1 1 -1 -1  2\n",
      "1 1 1 1 -1 -1 -1 -1  3\n",
      "1 1 1 -1 -1 -1 -1 -1  4\n",
      "1 1 -1 -1 -1 -1 -1 -1  5\n",
      "1 -1 1 1 1 1 -1 -1  6\n",
      "-1 -1 -1 -1 -1 -1 -1 -1  7\n",
      "0 1 2 3 4 5 6 7 \n",
      "\n",
      "Score Comp1: 31\n",
      "Score Comp2: 33\n",
      "\n",
      "9 번째 게임\n",
      "게임종료\n",
      "-1 1 1 1 1 -1 -1 -1  0\n",
      "-1 1 1 1 1 -1 -1 -1  1\n",
      "-1 1 -1 1 -1 -1 -1 -1  2\n",
      "-1 1 1 -1 -1 -1 1 -1  3\n",
      "-1 1 -1 -1 -1 1 -1 -1  4\n",
      "-1 1 -1 -1 -1 -1 1 -1  5\n",
      "-1 -1 1 1 1 1 -1 -1  6\n",
      "-1 -1 -1 -1 -1 -1 -1 -1  7\n",
      "0 1 2 3 4 5 6 7 \n",
      "\n",
      "Score Comp1: 21\n",
      "Score Comp2: 43\n",
      "\n",
      "10 번째 게임\n",
      "게임종료\n",
      "1 1 -1 -1 -1 -1 -1 0  0\n",
      "1 1 -1 -1 -1 -1 -1 -1  1\n",
      "1 1 -1 1 -1 1 -1 -1  2\n",
      "1 1 -1 1 1 -1 -1 -1  3\n",
      "1 1 1 -1 1 1 -1 -1  4\n",
      "1 1 -1 1 -1 1 -1 -1  5\n",
      "1 1 1 -1 1 -1 -1 -1  6\n",
      "1 1 1 1 1 1 -1 1  7\n",
      "0 1 2 3 4 5 6 7 \n",
      "\n",
      "Score Comp1: 32\n",
      "Score Comp2: 31\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#model = CnnDQN((8, 8), 8 * 8)\n",
    "model = torch.load('./20181207_220215.pt')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
    "\n",
    "replay_initial = 300\n",
    "replay_buffer = ReplayBuffer(10000)\n",
    "\n",
    "epsilon_start = 1.0\n",
    "epsilon_final = 0.01\n",
    "epsilon_decay = 30000\n",
    "\n",
    "epsilon_by_frame = lambda frame_idx: epsilon_final + (epsilon_start - epsilon_final) * math.exp(\n",
    "    -1. * frame_idx / epsilon_decay)\n",
    "\n",
    "n = 8  # board size (even)\n",
    "\n",
    "board = [['0' for x in range(n)] for y in range(n)]\n",
    "# 8 directions\n",
    "dirx = [-1, 0, 1, -1, 1, -1, 0, 1]\n",
    "diry = [-1, -1, -1, 0, 0, 1, 1, 1]\n",
    "\n",
    "opt = 2\n",
    "depth = 4\n",
    "\n",
    "num_frames = 14000\n",
    "batch_size = 32\n",
    "gamma = 0.99\n",
    "\n",
    "losses = []\n",
    "all_rewards = []\n",
    "episode_reward = 0\n",
    "\n",
    "\n",
    "def compute_td_loss(batch_size):\n",
    "    state, action, reward, next_state, done = replay_buffer.sample(batch_size)\n",
    "    \n",
    "    state = Variable(torch.FloatTensor(np.float32(state)))\n",
    "    next_state = Variable(torch.FloatTensor(np.float32(next_state)), volatile=True)\n",
    "    \n",
    "    action_list = []\n",
    "    for i in range(32):\n",
    "        action_idx = action[i][0]*8 + action[i][1]\n",
    "        action_list.append(action_idx)\n",
    "        \n",
    "    action = Variable(torch.LongTensor(action_list))\n",
    "    reward = Variable(torch.FloatTensor(reward))\n",
    "    done = Variable(torch.FloatTensor(done))\n",
    "\n",
    "    q_values = model(state)\n",
    "    next_q_values = model(next_state)\n",
    "\n",
    "    q_value = q_values.gather(1, action.unsqueeze(1)).squeeze(1)\n",
    "    next_q_value = next_q_values.max(1)[0]\n",
    "    expected_q_value = reward + gamma * next_q_value * (1 - done)\n",
    "\n",
    "    loss = (q_value - Variable(expected_q_value.data)).pow(2).mean()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def plot(frame_idx, rewards, losses):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.subplot(131)\n",
    "    plt.title('frame %s. reward: %s' % (frame_idx, np.mean(rewards[-10:])))\n",
    "    plt.plot(rewards)\n",
    "    plt.subplot(132)\n",
    "    plt.title('loss')\n",
    "    plt.plot(losses)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def InitBoard():\n",
    "    if n % 2 == 0:  # if board size is even\n",
    "        z = int((n - 2) / 2)\n",
    "        board[z][z] = '-1'\n",
    "        board[n - 1 - z][z] = '1'\n",
    "        board[z][n - 1 - z] = '1'\n",
    "        board[n - 1 - z][n - 1 - z] = '-1'\n",
    "\n",
    "\n",
    "def PrintBoard():\n",
    "    m = len(str(n - 1))\n",
    "    for y in range(n):\n",
    "        row = ''\n",
    "        for x in range(n):\n",
    "            row += board[y][x]\n",
    "            row += ' ' * m\n",
    "        print(row + ' ' + str(y))\n",
    "    print\n",
    "    row = ''\n",
    "    for x in range(n):\n",
    "        row += str(x).zfill(m) + ' '\n",
    "    print(row + '\\n')\n",
    "\n",
    "\n",
    "def MakeMove(board, x, y, player):  # assuming valid move\n",
    "    totctr = 0  # total number of opponent pieces taken\n",
    "    board[y][x] = player\n",
    "    for d in range(8):  # 8 directions\n",
    "        ctr = 0\n",
    "        for i in range(n):\n",
    "            dx = x + dirx[d] * (i + 1)\n",
    "            dy = y + diry[d] * (i + 1)\n",
    "            if dx < 0 or dx > n - 1 or dy < 0 or dy > n - 1:\n",
    "                ctr = 0;\n",
    "                break\n",
    "            elif board[dy][dx] == player:\n",
    "                break\n",
    "            elif board[dy][dx] == '0':\n",
    "                ctr = 0;\n",
    "                break\n",
    "            else:\n",
    "                ctr += 1\n",
    "        for i in range(ctr):\n",
    "            dx = x + dirx[d] * (i + 1)\n",
    "            dy = y + diry[d] * (i + 1)\n",
    "            board[dy][dx] = player\n",
    "        totctr += ctr\n",
    "    return (board, totctr)\n",
    "\n",
    "\n",
    "def ValidMove(board, x, y, player):\n",
    "    if x < 0 or x > n - 1 or y < 0 or y > n - 1:\n",
    "        return False\n",
    "    if board[y][x] != '0':\n",
    "        return False\n",
    "    (boardTemp, totctr) = MakeMove(copy.deepcopy(board), x, y, player)\n",
    "    if totctr == 0:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "minEvalBoard = -1  # min - 1\n",
    "maxEvalBoard = n * n + 4 * n + 4 + 1  # max + 1\n",
    "\n",
    "\n",
    "def EvalBoard(board, player):\n",
    "    tot = 0\n",
    "    for y in range(n):\n",
    "        for x in range(n):\n",
    "            if board[y][x] == player:\n",
    "                tot += 1\n",
    "    return tot\n",
    "\n",
    "\n",
    "def IsTerminalNode(board, player):\n",
    "    for y in range(n):\n",
    "        for x in range(n):\n",
    "            if ValidMove(board, x, y, player):\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def BestMove(board, player):\n",
    "    maxPoints = 0\n",
    "    mx = -1;\n",
    "    my = -1\n",
    "    for y in range(n):\n",
    "        for x in range(n):\n",
    "            if ValidMove(board, x, y, player):\n",
    "                (boardTemp, totctr) = MakeMove(copy.deepcopy(board), x, y, player)\n",
    "                points = AlphaBeta(board, player, depth, minEvalBoard, maxEvalBoard, True)\n",
    "                if points > maxPoints:\n",
    "                    maxPoints = points\n",
    "                    mx = x;\n",
    "                    my = y\n",
    "    return (mx, my)\n",
    "\n",
    "\n",
    "def AlphaBeta(board, player, depth, alpha, beta, maximizingPlayer):\n",
    "    if depth == 0 or IsTerminalNode(board, player):\n",
    "        return EvalBoard(board, player)\n",
    "    if maximizingPlayer:\n",
    "        v = minEvalBoard\n",
    "        for y in range(n):\n",
    "            for x in range(n):\n",
    "                if ValidMove(board, x, y, player):\n",
    "                    (boardTemp, totctr) = MakeMove(copy.deepcopy(board), x, y, player)\n",
    "                    v = max(v, AlphaBeta(boardTemp, player, depth - 1, alpha, beta, False))\n",
    "                    alpha = max(alpha, v)\n",
    "                    if beta <= alpha:\n",
    "                        break  # beta cut-off\n",
    "        return v\n",
    "    else:  # minimizingPlayer\n",
    "        v = maxEvalBoard\n",
    "        for y in range(n):\n",
    "            for x in range(n):\n",
    "                if ValidMove(board, x, y, player):\n",
    "                    (boardTemp, totctr) = MakeMove(copy.deepcopy(board), x, y, player)\n",
    "                    v = min(v, AlphaBeta(boardTemp, player, depth - 1, alpha, beta, True))\n",
    "                    beta = min(beta, v)\n",
    "                    if beta <= alpha:\n",
    "                        break  # alpha cut-off\n",
    "        return v\n",
    "\n",
    "\n",
    "def GetSortedNodes(board, player):\n",
    "    sortedNodes = []\n",
    "    for y in range(n):\n",
    "        for x in range(n):\n",
    "            if ValidMove(board, x, y, player):\n",
    "                (boardTemp, totctr) = MakeMove(copy.deepcopy(board), x, y, player)\n",
    "                sortedNodes.append((boardTemp, EvalBoard(boardTemp, player)))\n",
    "    sortedNodes = sorted(sortedNodes, key=lambda node: node[1], reverse=True)\n",
    "    sortedNodes = [node[0] for node in sortedNodes]\n",
    "    return sortedNodes\n",
    "\n",
    "\n",
    "def get_validlist(board, player):\n",
    "    validlist = []\n",
    "    for x in range(8):\n",
    "        for y in range(8):\n",
    "            if ValidMove(board, x, y, player):\n",
    "                validlist.append([x, y])\n",
    "    return validlist\n",
    "\n",
    "\n",
    "def random_agent(board, player):\n",
    "    validlist = get_validlist(board, player)\n",
    "    random.shuffle(validlist)\n",
    "    (x, y) = validlist.pop()\n",
    "    x = int(x)\n",
    "    y = int(y)\n",
    "    (board, totctr) = MakeMove(board, x, y, player)\n",
    "#     print('player' + player + 'played (X Y): ' + str(x) + ' ' + str(y))\n",
    "#     print('# of pieces taken: ' + str(totctr))\n",
    "#     PrintBoard()\n",
    "\n",
    "\n",
    "def alphabeta_agent(board, player):\n",
    "    (x, y) = BestMove(board, player)\n",
    "    if not (x == -1 and y == -1):\n",
    "        (board, totctr) = MakeMove(board, x, y, player)\n",
    "        print('AlphaBeta played (X Y): ' + str(x) + ' ' + str(y))\n",
    "        print('# of pieces taken: ' + str(totctr))\n",
    "\n",
    "all_rewards = []\n",
    "num_episode = 10\n",
    "terminal = False\n",
    "for i in range(num_episode):\n",
    "\n",
    "    # for frame_idx in range(1, num_frames+1):\n",
    "    state = [['0' for x in range(n)] for y in range(n)]\n",
    "    board = [['0' for x in range(n)] for y in range(n)]\n",
    "    InitBoard()\n",
    "    terminal = False\n",
    "    print(i+1,\"번째 게임\")\n",
    "#     PrintBoard()\n",
    "    # 한 게임\n",
    "\n",
    "    while not terminal:\n",
    "        for p in range(2):\n",
    "            print\n",
    "            if p == 0:\n",
    "                player = str(p+1)\n",
    "            else:\n",
    "                player = '-1'\n",
    "#             print('PLAYER: ' + player)\n",
    "\n",
    "            if player == '1':  # computer1's turn\n",
    "                \n",
    "                if IsTerminalNode(board, player):\n",
    "                    terminal = True\n",
    "                else:\n",
    "                    terminal = False\n",
    "                    random_agent(board, player)\n",
    "\n",
    "            else:  # computer2's turn (학습시킬아이) -1\n",
    "                if IsTerminalNode(board, player):\n",
    "                    terminal = True\n",
    "                else:\n",
    "                    terminal = False\n",
    "                    state = copy.deepcopy(board)\n",
    "                    \n",
    "                    epsilon = epsilon_by_frame(i)\n",
    "                    validlist = get_validlist(board, player)\n",
    "                    action = model.act(state, epsilon, validlist)  # return (x,y)\n",
    "                    x = action[0]\n",
    "                    y = action[1]\n",
    "                    \n",
    "                    (board, totctr) = MakeMove(board, x, y, player)\n",
    "                    # terminal 체크\n",
    "\n",
    "\n",
    "                    next_state, reward, done = board, 0, terminal\n",
    "\n",
    "                    # 이걸 리스트에 다 넣고\n",
    "                    replay_buffer.push(state, action, reward, next_state, done)\n",
    "\n",
    "\n",
    "#                     print('player' + player + 'played (X Y): ' + str(x) + ' ' + str(y))\n",
    "#                     print('# of pieces taken: ' + str(totctr))\n",
    "#                     PrintBoard()\n",
    "\n",
    "    # 한 게임이 끝났을 때\n",
    "    # 에피소드 list의 마지막 done을 True로 바꾸고 그걸 buffer로 바꾸기\n",
    "    replay_buffer.change_last_done()\n",
    "    print('게임종료')\n",
    "    PrintBoard()\n",
    "    print('Score Comp1: ' + str(EvalBoard(board, '1')))\n",
    "    print('Score Comp2: ' + str(EvalBoard(board, '-1')))\n",
    "    print(\"\")\n",
    "    \n",
    "    if EvalBoard(board, '-1') > EvalBoard(board, '1'):\n",
    "        reward = 10\n",
    "    elif EvalBoard(board, '-1') == EvalBoard(board, '1'):\n",
    "        reward = 0\n",
    "    else:\n",
    "        reward = -5\n",
    "        \n",
    "    all_rewards.append(reward)\n",
    "    reward = 0\n",
    "    \n",
    "    if len(replay_buffer) > replay_initial:\n",
    "        if num_episode % 5 == 0:\n",
    "            loss = compute_td_loss(batch_size)\n",
    "            losses.append(loss.data[0].item())\n",
    "            \n",
    "    if i % 5 == 0:\n",
    "        # all_rewards를 평균으로하면 더 좋을듯. 근데 그럼 x축도 바꿔야함\n",
    "        # 왜냐면 지금 x축은 에피소드 개수이기 때문\n",
    "        plot(i, all_rewards, losses)\n",
    "        now = datetime.today().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        torch.save(model, \"./save/\"+now+\".pt\")\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
