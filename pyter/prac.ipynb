{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, copy\n",
    "import math, random\n",
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "from collections import deque\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "#쿠다 사용시 RuntimeError: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same 애러\n",
    "USE_CUDA = False\n",
    "Variable = lambda *args, **kwargs: autograd.Variable(*args, **kwargs).cuda() if USE_CUDA else autograd.Variable(*args,\n",
    "                                                                                                                **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ReplayBuffer(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "\n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        state = np.expand_dims(state, 0)\n",
    "        next_state = np.expand_dims(next_state, 0)\n",
    "\n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        state, action, reward, next_state, done = zip(*random.sample(self.buffer, batch_size))\n",
    "        return np.concatenate(state), action, reward, np.concatenate(next_state), done\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "    \n",
    "    def change_last_done(self):\n",
    "        last = list(self.buffer[-1])\n",
    "        last[4] = True\n",
    "        self.buffer.pop()\n",
    "        self.buffer.append(last)\n",
    "        \n",
    "    def get_last(self):\n",
    "        return self.buffer[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CnnDQN(nn.Module):\n",
    "    def __init__(self, input_shape, num_actions):\n",
    "        super(CnnDQN, self).__init__()\n",
    "\n",
    "        self.input_shape = input_shape  # 8*8 state(observation) size\n",
    "        self.num_actions = num_actions  # 8*8 action size 난 똑같\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(4, 32, kernel_size=3, stride=1),\n",
    "            # output는 6*6\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # fully connected = 그냥 신경망\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(32*6*6, 24),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(24, self.num_actions)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def feature_size(self):\n",
    "        return self.features(autograd.Variable(torch.zeros(32,1, *self.input_shape))).view(1, -1).size(1)\n",
    "\n",
    "    def act(self, state, epsilon, validlist):\n",
    "        if random.random() > epsilon:\n",
    "            state = np.expand_dims(np.float32(state), 0)\n",
    "            state = Variable(torch.FloatTensor(state), volatile=True)\n",
    "            \n",
    "            q_value = self.forward(state)  # size 64의 linear [1,2,3,4]\n",
    "            # q_value에서 valid 한 것만 놔두기.\n",
    "            valid_q_value = []\n",
    "#             print(q_value)\n",
    "            for i in validlist:\n",
    "                idx = i[0]*8 + i[1]\n",
    "                valid_q_value.append(q_value[0, idx])\n",
    "                \n",
    "            # action = valid_q_value.max(1)[1].data[0]\n",
    "            val = np.max(valid_q_value)\n",
    "            val_idx = (q_value[0] == val).nonzero().item()\n",
    "            # 해당 인덱스의 좌표 찾기\n",
    "            x = int(val_idx//8)\n",
    "            y = int(val_idx % 8)\n",
    "            action = (x, y)\n",
    "\n",
    "        else:\n",
    "            random.shuffle(validlist)\n",
    "            (x, y) = validlist.pop()\n",
    "            x = int(x)\n",
    "            y = int(y)\n",
    "            action = (x, y)\n",
    "\n",
    "        return action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_td_loss(batch_size):\n",
    "    state, action, reward, next_state, done = replay_buffer.sample(batch_size)\n",
    "    \n",
    "    state = Variable(torch.FloatTensor(np.float32(state)))\n",
    "    next_state = Variable(torch.FloatTensor(np.float32(next_state)), volatile=True)\n",
    "    \n",
    "    action_list = []\n",
    "    for i in range(32):\n",
    "        action_idx = action[i][0]*8 + action[i][1]\n",
    "        action_list.append(action_idx)\n",
    "        \n",
    "    action = Variable(torch.LongTensor(action_list))\n",
    "    reward = Variable(torch.FloatTensor(reward))\n",
    "    done = Variable(torch.FloatTensor(done))\n",
    "\n",
    "    q_values = model(state)\n",
    "    next_q_values = model(next_state)\n",
    "\n",
    "    q_value = q_values.gather(1, action.unsqueeze(1)).squeeze(1)\n",
    "    next_q_value = next_q_values.max(1)[0]\n",
    "    expected_q_value = reward + gamma * next_q_value * (1 - done)\n",
    "\n",
    "    loss = (q_value - Variable(expected_q_value.data)).pow(2).mean()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def plot(frame_idx, mean_rewards, losses):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.subplot(131)\n",
    "    plt.title('frame %s. reward: %s' % (frame_idx, mean_rewards[-1:]))\n",
    "    plt.plot(mean_rewards)\n",
    "    plt.subplot(132)\n",
    "    plt.title('loss')\n",
    "    plt.plot(losses)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def InitBoard():\n",
    "    if n % 2 == 0:  # if board size is even\n",
    "        z = int((n - 2) / 2)\n",
    "        board[z][z] = '-1'\n",
    "        board[n - 1 - z][z] = '1'\n",
    "        board[z][n - 1 - z] = '1'\n",
    "        board[n - 1 - z][n - 1 - z] = '-1'\n",
    "\n",
    "\n",
    "def PrintBoard():\n",
    "    m = len(str(n - 1))\n",
    "    for y in range(n):\n",
    "        row = ''\n",
    "        for x in range(n):\n",
    "            row += board[y][x]\n",
    "            row += ' ' * m\n",
    "        print(row + ' ' + str(y))\n",
    "    print\n",
    "    row = ''\n",
    "    for x in range(n):\n",
    "        row += str(x).zfill(m) + ' '\n",
    "    print(row + '\\n')\n",
    "\n",
    "\n",
    "def MakeMove(board, x, y, player):  # assuming valid move\n",
    "    totctr = 0  # total number of opponent pieces taken\n",
    "    board[y][x] = player\n",
    "    for d in range(8):  # 8 directions\n",
    "        ctr = 0\n",
    "        for i in range(n):\n",
    "            dx = x + dirx[d] * (i + 1)\n",
    "            dy = y + diry[d] * (i + 1)\n",
    "            if dx < 0 or dx > n - 1 or dy < 0 or dy > n - 1:\n",
    "                ctr = 0;\n",
    "                break\n",
    "            elif board[dy][dx] == player:\n",
    "                break\n",
    "            elif board[dy][dx] == '0':\n",
    "                ctr = 0;\n",
    "                break\n",
    "            else:\n",
    "                ctr += 1\n",
    "        for i in range(ctr):\n",
    "            dx = x + dirx[d] * (i + 1)\n",
    "            dy = y + diry[d] * (i + 1)\n",
    "            board[dy][dx] = player\n",
    "        totctr += ctr\n",
    "    return (board, totctr)\n",
    "\n",
    "\n",
    "def ValidMove(board, x, y, player):\n",
    "    if x < 0 or x > n - 1 or y < 0 or y > n - 1:\n",
    "        return False\n",
    "    if board[y][x] != '0':\n",
    "        return False\n",
    "    (boardTemp, totctr) = MakeMove(copy.deepcopy(board), x, y, player)\n",
    "    if totctr == 0:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def EvalBoard(board, player):\n",
    "    tot = 0\n",
    "    for y in range(n):\n",
    "        for x in range(n):\n",
    "            if board[y][x] == player:\n",
    "                tot += 1\n",
    "    return tot\n",
    "\n",
    "def IsTerminalNode(board, player):\n",
    "    for y in range(n):\n",
    "        for x in range(n):\n",
    "            if ValidMove(board, x, y, player):\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "def BestMove(board, player):\n",
    "    maxPoints = 0\n",
    "    mx = -1;\n",
    "    my = -1\n",
    "    for y in range(n):\n",
    "        for x in range(n):\n",
    "            if ValidMove(board, x, y, player):\n",
    "                (boardTemp, totctr) = MakeMove(copy.deepcopy(board), x, y, player)\n",
    "                points = AlphaBeta(board, player, depth, minEvalBoard, maxEvalBoard, True)\n",
    "                if points > maxPoints:\n",
    "                    maxPoints = points\n",
    "                    mx = x;\n",
    "                    my = y\n",
    "    return (mx, my)\n",
    "\n",
    "\n",
    "def AlphaBeta(board, player, depth, alpha, beta, maximizingPlayer):\n",
    "    if depth == 0 or IsTerminalNode(board, player):\n",
    "        return EvalBoard(board, player)\n",
    "    if maximizingPlayer:\n",
    "        v = minEvalBoard\n",
    "        for y in range(n):\n",
    "            for x in range(n):\n",
    "                if ValidMove(board, x, y, player):\n",
    "                    (boardTemp, totctr) = MakeMove(copy.deepcopy(board), x, y, player)\n",
    "                    v = max(v, AlphaBeta(boardTemp, player, depth - 1, alpha, beta, False))\n",
    "                    alpha = max(alpha, v)\n",
    "                    if beta <= alpha:\n",
    "                        break  # beta cut-off\n",
    "        return v\n",
    "    else:  # minimizingPlayer\n",
    "        v = maxEvalBoard\n",
    "        for y in range(n):\n",
    "            for x in range(n):\n",
    "                if ValidMove(board, x, y, player):\n",
    "                    (boardTemp, totctr) = MakeMove(copy.deepcopy(board), x, y, player)\n",
    "                    v = min(v, AlphaBeta(boardTemp, player, depth - 1, alpha, beta, True))\n",
    "                    beta = min(beta, v)\n",
    "                    if beta <= alpha:\n",
    "                        break  # alpha cut-off\n",
    "        return v\n",
    "\n",
    "\n",
    "def GetSortedNodes(board, player):\n",
    "    sortedNodes = []\n",
    "    for y in range(n):\n",
    "        for x in range(n):\n",
    "            if ValidMove(board, x, y, player):\n",
    "                (boardTemp, totctr) = MakeMove(copy.deepcopy(board), x, y, player)\n",
    "                sortedNodes.append((boardTemp, EvalBoard(boardTemp, player)))\n",
    "    sortedNodes = sorted(sortedNodes, key=lambda node: node[1], reverse=True)\n",
    "    sortedNodes = [node[0] for node in sortedNodes]\n",
    "    return sortedNodes\n",
    "\n",
    "\n",
    "def get_validlist(board, player):\n",
    "    validlist = []\n",
    "    for x in range(8):\n",
    "        for y in range(8):\n",
    "            if ValidMove(board, x, y, player):\n",
    "                validlist.append([x, y])\n",
    "    return validlist\n",
    "\n",
    "\n",
    "def random_agent(board, player):\n",
    "    validlist = get_validlist(board, player)\n",
    "    random.shuffle(validlist)\n",
    "    (x, y) = validlist.pop()\n",
    "    x = int(x)\n",
    "    y = int(y)\n",
    "    (board, totctr) = MakeMove(board, x, y, player)\n",
    "#     print('player' + player + 'played (X Y): ' + str(x) + ' ' + str(y))\n",
    "#     print('# of pieces taken: ' + str(totctr))\n",
    "#     PrintBoard()\n",
    "\n",
    "\n",
    "def alphabeta_agent(board, player):\n",
    "    (x, y) = BestMove(board, player)\n",
    "    if not (x == -1 and y == -1):\n",
    "        (board, totctr) = MakeMove(board, x, y, player)\n",
    "        print('AlphaBeta played (X Y): ' + str(x) + ' ' + str(y))\n",
    "        print('# of pieces taken: ' + str(totctr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random VS DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = CnnDQN((8, 8), 8 * 8)\n",
    "model = torch.load('../save/20181216_023330.pt')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
    "\n",
    "replay_initial = 300\n",
    "replay_buffer = ReplayBuffer(10000)\n",
    "\n",
    "epsilon_start = 1.0\n",
    "epsilon_final = 0.01\n",
    "epsilon_decay = 10000\n",
    "\n",
    "epsilon_by_frame = lambda frame_idx: epsilon_final + (epsilon_start - epsilon_final) * math.exp(\n",
    "    -1. * frame_idx / epsilon_decay)\n",
    "\n",
    "n = 8  # board size (even)\n",
    "\n",
    "board = [['0' for x in range(n)] for y in range(n)]\n",
    "# 8 directions\n",
    "dirx = [-1, 0, 1, -1, 1, -1, 0, 1]\n",
    "diry = [-1, -1, -1, 0, 0, 1, 1, 1]\n",
    "\n",
    "opt = 2\n",
    "depth = 4\n",
    "\n",
    "num_frames = 14000\n",
    "batch_size = 32\n",
    "gamma = 0.99\n",
    "\n",
    "losses = []\n",
    "all_rewards = []\n",
    "episode_reward = 0\n",
    "\n",
    "minEvalBoard = -1  # min - 1\n",
    "maxEvalBoard = n * n + 4 * n + 4 + 1  # max + 1\n",
    "\n",
    "all_rewards = []\n",
    "mean_rewards = []\n",
    "state_save = []\n",
    "num_episode = 100\n",
    "terminal = False\n",
    "for i in range(num_episode):\n",
    "    \n",
    "    # for frame_idx in range(1, num_frames+1):\n",
    "    state = [['0' for x in range(n)] for y in range(n)]\n",
    "    board = [['0' for x in range(n)] for y in range(n)]\n",
    "    InitBoard()\n",
    "    terminal = False\n",
    "    print(i+1,\"번째 게임\")\n",
    "#     PrintBoard()\n",
    "    # 한 게임\n",
    "\n",
    "    while not terminal:\n",
    "        for p in range(2):\n",
    "            print\n",
    "            if p == 0:\n",
    "                player = str(p+1)\n",
    "            else:\n",
    "                player = '-1'\n",
    "#             print('PLAYER: ' + player)\n",
    "\n",
    "            if player == '1':  # computer1's turn\n",
    "                \n",
    "                if IsTerminalNode(board, player):\n",
    "                    terminal = True\n",
    "                else:\n",
    "                    terminal = False\n",
    "                    random_agent(board, player)\n",
    "\n",
    "            else:  # computer2's turn (학습시킬아이) -1\n",
    "                if IsTerminalNode(board, player):\n",
    "                    terminal = True\n",
    "                else:\n",
    "                    terminal = False\n",
    "                    if (EvalBoard(board, '1') + EvalBoard(board, '-1') == 5): # 첫수 둘때\n",
    "                        state = copy.deepcopy(board)\n",
    "                        state = np.expand_dims(state, 0)\n",
    "                        state = np.concatenate((state, state,state,state),axis=0)\n",
    "                        state_save.append(state)\n",
    "                        \n",
    "                    else: # 첫 수 이후\n",
    "                        state = copy.deepcopy(board)\n",
    "                        state_save[-1][-1] = state\n",
    "                        state = state_save[-1]\n",
    "\n",
    "                    epsilon = epsilon_by_frame(i)\n",
    "                    validlist = get_validlist(board, player)\n",
    "                    action = model.act(state, epsilon, validlist)  # return (x,y)\n",
    "                    x = action[0]\n",
    "                    y = action[1]\n",
    "\n",
    "                    (board, totctr) = MakeMove(board, x, y, player)\n",
    "                    # terminal 체크\n",
    "\n",
    "                    next_state = copy.deepcopy(board)\n",
    "                    next_state = np.expand_dims(next_state, 0)\n",
    "                    next_state = np.concatenate((next_state, next_state, next_state, next_state),axis=0)\n",
    "                    next_state, reward, done = next_state, 0, terminal\n",
    "                    \n",
    "                    # 이걸 리스트에 다 넣고\n",
    "                    replay_buffer.push(state, action, reward, next_state, done)\n",
    "\n",
    "\n",
    "#                     print('player' + player + 'played (X Y): ' + str(x) + ' ' + str(y))\n",
    "#                     print('# of pieces taken: ' + str(totctr))\n",
    "#                     PrintBoard()\n",
    "\n",
    "    # 한 게임이 끝났을 때\n",
    "    # 에피소드 list의 마지막 done을 True로 바꾸고 그걸 buffer로 바꾸기\n",
    "    replay_buffer.change_last_done()\n",
    "    print('게임종료')\n",
    "    PrintBoard()\n",
    "    print('Score Comp1: ' + str(EvalBoard(board, '1')))\n",
    "    print('Score Comp2: ' + str(EvalBoard(board, '-1')))\n",
    "    print(\"\")\n",
    "    \n",
    "    if EvalBoard(board, '-1') > EvalBoard(board, '1'):\n",
    "        reward = 1\n",
    "    elif EvalBoard(board, '-1') == EvalBoard(board, '1'):\n",
    "        reward = 0\n",
    "    else:\n",
    "        reward = -1\n",
    "        \n",
    "    all_rewards.append(reward)\n",
    "    reward = 0\n",
    "    \n",
    "    if len(replay_buffer) > replay_initial:\n",
    "        if num_episode % 10 == 0:\n",
    "            loss = compute_td_loss(batch_size)\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "    if i % 10 == 0:\n",
    "        mean_rewards.append(np.mean(all_rewards[-10:]))\n",
    "        plot(i, mean_rewards, losses)\n",
    "#         now = datetime.today().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        #torch.save(model, \"../save/\"+now+\".pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlphaBeta VS DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAwMAAAE/CAYAAAAaBR/cAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2d1253d58d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402 번째 게임\n",
      "게임종료\n",
      "1 1 1 1 1 1 -1 -1  0\n",
      "1 1 1 1 1 1 -1 -1  1\n",
      "1 -1 -1 1 1 1 -1 -1  2\n",
      "1 -1 1 -1 -1 1 -1 -1  3\n",
      "1 1 -1 -1 1 1 -1 -1  4\n",
      "1 1 1 -1 -1 -1 -1 -1  5\n",
      "1 1 1 -1 -1 -1 -1 1  6\n",
      "1 1 -1 -1 -1 -1 -1 -1  7\n",
      "0 1 2 3 4 5 6 7 \n",
      "\n",
      "Score Comp1: 32\n",
      "Score Comp2: 32\n",
      "\n",
      "403 번째 게임\n",
      "게임종료\n",
      "-1 -1 -1 -1 -1 -1 -1 -1  0\n",
      "-1 -1 -1 -1 -1 1 -1 1  1\n",
      "-1 1 1 1 1 1 1 1  2\n",
      "-1 -1 -1 -1 -1 -1 -1 -1  3\n",
      "-1 -1 -1 -1 -1 -1 -1 0  4\n",
      "0 -1 0 0 0 0 0 0  5\n",
      "-1 0 0 0 0 0 0 0  6\n",
      "0 0 0 0 0 0 0 0  7\n",
      "0 1 2 3 4 5 6 7 \n",
      "\n",
      "Score Comp1: 9\n",
      "Score Comp2: 32\n",
      "\n",
      "404 번째 게임\n",
      "게임종료\n",
      "-1 -1 -1 -1 -1 -1 -1 -1  0\n",
      "-1 -1 -1 1 1 -1 1 1  1\n",
      "-1 -1 -1 -1 -1 1 1 1  2\n",
      "-1 -1 -1 -1 -1 1 1 1  3\n",
      "-1 -1 -1 -1 1 -1 1 1  4\n",
      "-1 -1 -1 -1 -1 -1 -1 1  5\n",
      "-1 0 -1 0 -1 -1 0 -1  6\n",
      "0 0 0 0 0 0 0 0  7\n",
      "0 1 2 3 4 5 6 7 \n",
      "\n",
      "Score Comp1: 14\n",
      "Score Comp2: 39\n",
      "\n",
      "405 번째 게임\n",
      "게임종료\n",
      "-1 1 1 1 1 1 1 -1  0\n",
      "-1 -1 -1 -1 1 -1 1 -1  1\n",
      "-1 -1 -1 1 1 1 1 -1  2\n",
      "-1 -1 -1 -1 1 1 -1 -1  3\n",
      "-1 -1 -1 -1 -1 1 -1 -1  4\n",
      "-1 -1 -1 1 -1 1 1 -1  5\n",
      "-1 -1 -1 -1 1 -1 -1 -1  6\n",
      "1 1 1 1 1 1 -1 -1  7\n",
      "0 1 2 3 4 5 6 7 \n",
      "\n",
      "Score Comp1: 25\n",
      "Score Comp2: 39\n",
      "\n",
      "406 번째 게임\n",
      "게임종료\n",
      "1 1 1 1 0 0 0 0  0\n",
      "1 1 1 -1 -1 0 0 0  1\n",
      "1 -1 1 -1 0 0 0 0  2\n",
      "0 -1 -1 -1 -1 -1 0 0  3\n",
      "-1 -1 -1 -1 -1 0 0 0  4\n",
      "0 -1 0 0 0 0 0 0  5\n",
      "-1 0 0 0 0 0 0 0  6\n",
      "0 0 0 0 0 0 0 0  7\n",
      "0 1 2 3 4 5 6 7 \n",
      "\n",
      "Score Comp1: 9\n",
      "Score Comp2: 16\n",
      "\n",
      "407 번째 게임\n",
      "게임종료\n",
      "1 1 1 1 1 1 1 1  0\n",
      "1 1 1 1 1 -1 1 1  1\n",
      "-1 1 1 1 -1 -1 0 0  2\n",
      "0 0 0 -1 -1 -1 0 0  3\n",
      "0 -1 -1 -1 -1 0 0 0  4\n",
      "0 -1 0 0 0 0 0 0  5\n",
      "0 -1 0 0 0 0 0 0  6\n",
      "0 0 0 0 0 0 0 0  7\n",
      "0 1 2 3 4 5 6 7 \n",
      "\n",
      "Score Comp1: 18\n",
      "Score Comp2: 13\n",
      "\n",
      "408 번째 게임\n",
      "게임종료\n",
      "1 1 1 1 1 1 1 0  0\n",
      "1 1 1 1 -1 -1 0 0  1\n",
      "1 1 -1 -1 -1 0 0 0  2\n",
      "0 0 -1 -1 -1 0 0 0  3\n",
      "0 0 -1 -1 -1 -1 0 0  4\n",
      "0 0 0 0 0 0 0 0  5\n",
      "0 0 0 0 0 0 0 0  6\n",
      "0 0 0 0 0 0 0 0  7\n",
      "0 1 2 3 4 5 6 7 \n",
      "\n",
      "Score Comp1: 13\n",
      "Score Comp2: 12\n",
      "\n",
      "409 번째 게임\n"
     ]
    }
   ],
   "source": [
    "#model = CnnDQN((8, 8), 8 * 8)\n",
    "model = torch.load('../save/20181216_024659.pt')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
    "\n",
    "replay_initial = 300\n",
    "replay_buffer = ReplayBuffer(10000)\n",
    "\n",
    "epsilon_start = 0.9\n",
    "epsilon_final = 0.01\n",
    "epsilon_decay = 1000\n",
    "\n",
    "epsilon_by_frame = lambda frame_idx: epsilon_final + (epsilon_start - epsilon_final) * math.exp(\n",
    "    -1. * frame_idx / epsilon_decay)\n",
    "\n",
    "n = 8  # board size (even)\n",
    "\n",
    "board = [['0' for x in range(n)] for y in range(n)]\n",
    "# 8 directions\n",
    "dirx = [-1, 0, 1, -1, 1, -1, 0, 1]\n",
    "diry = [-1, -1, -1, 0, 0, 1, 1, 1]\n",
    "\n",
    "opt = 2\n",
    "depth = 3\n",
    "\n",
    "num_frames = 14000\n",
    "batch_size = 32\n",
    "gamma = 0.99\n",
    "\n",
    "losses = []\n",
    "all_rewards = []\n",
    "episode_reward = 0\n",
    "\n",
    "minEvalBoard = -1  # min - 1\n",
    "maxEvalBoard = n * n + 4 * n + 4 + 1  # max + 1\n",
    "\n",
    "all_rewards = []\n",
    "mean_rewards = []\n",
    "state_save = []\n",
    "num_episode = 1001\n",
    "terminal = False\n",
    "for i in range(num_episode):\n",
    "\n",
    "    # for frame_idx in range(1, num_frames+1):\n",
    "    state = [['0' for x in range(n)] for y in range(n)]\n",
    "    board = [['0' for x in range(n)] for y in range(n)]\n",
    "    InitBoard()\n",
    "    terminal = False\n",
    "    print(i+1,\"번째 게임\")\n",
    "#     PrintBoard()\n",
    "    # 한 게임\n",
    "    count = 0\n",
    "    while not terminal:\n",
    "        for p in range(2):\n",
    "            \n",
    "            if p == 0:\n",
    "                player = str(p+1)\n",
    "            else:\n",
    "                player = '-1'\n",
    "#             print('PLAYER: ' + player)\n",
    "\n",
    "            if player == '1':  # computer1's turn\n",
    "                \n",
    "                if IsTerminalNode(board, player):\n",
    "                    terminal = True\n",
    "                else:\n",
    "                    terminal = False\n",
    "                    count=count+1\n",
    "                    if(count<6):\n",
    "                        depth=1\n",
    "                    else:\n",
    "                        depth=3\n",
    "                    (x, y) = BestMove(board, player)\n",
    "                    if not (x == -1 and y == -1):\n",
    "                        (board, totctr) = MakeMove(board, x, y, player)\n",
    "\n",
    "            else:  # computer2's turn (학습시킬아이) -1\n",
    "                if IsTerminalNode(board, player):\n",
    "                    terminal = True\n",
    "                else:\n",
    "                    terminal = False\n",
    "                    if (EvalBoard(board, '1') + EvalBoard(board, '-1') == 5): # 첫수 둘때\n",
    "                        state = copy.deepcopy(board)\n",
    "                        state = np.expand_dims(state, 0)\n",
    "                        state = np.concatenate((state, state,state,state),axis=0)\n",
    "                        state_save.append(state)\n",
    "                        \n",
    "                    else: # 첫 수 이후\n",
    "                        state = copy.deepcopy(board)\n",
    "                        state_save[-1][-1] = state\n",
    "                        state = state_save[-1]\n",
    "                    \n",
    "                    epsilon = epsilon_by_frame(i)\n",
    "                    validlist = get_validlist(board, player)\n",
    "                    action = model.act(state, epsilon, validlist)  # return (x,y)\n",
    "                    x = action[0]\n",
    "                    y = action[1]\n",
    "                    \n",
    "                    (board, totctr) = MakeMove(board, x, y, player)\n",
    "                    # terminal 체크\n",
    "                    \n",
    "                    # next_state도 4개쌓기\n",
    "                    next_state = copy.deepcopy(board)\n",
    "                    next_state = np.expand_dims(next_state, 0)\n",
    "                    next_state = np.concatenate((next_state, next_state, next_state, next_state),axis=0)\n",
    "                    \n",
    "                    next_state, reward, done = next_state, 0, terminal\n",
    "\n",
    "                    # 이걸 리스트에 다 넣고\n",
    "                    replay_buffer.push(state, action, reward, next_state, done)\n",
    "\n",
    "#                     print('player' + player + 'played (X Y): ' + str(x) + ' ' + str(y))\n",
    "#                     print('# of pieces taken: ' + str(totctr))\n",
    "#                     PrintBoard()\n",
    "\n",
    "    # 한 게임이 끝났을 때\n",
    "    # 에피소드 list의 마지막 done을 True로 바꾸고 그걸 buffer로 바꾸기\n",
    "    replay_buffer.change_last_done()\n",
    "    print('게임종료')\n",
    "    PrintBoard()\n",
    "    print('Score Comp1: ' + str(EvalBoard(board, '1')))\n",
    "    print('Score Comp2: ' + str(EvalBoard(board, '-1')))\n",
    "    print(\"\")\n",
    "    \n",
    "    if EvalBoard(board, '-1') > EvalBoard(board, '1'):\n",
    "        reward = 1\n",
    "    elif EvalBoard(board, '-1') == EvalBoard(board, '1'):\n",
    "        reward = 0\n",
    "    else:\n",
    "        reward = -1\n",
    "        \n",
    "    all_rewards.append(reward)\n",
    "    reward = 0\n",
    "    \n",
    "\n",
    "    \n",
    "    if len(replay_buffer) > replay_initial:\n",
    "        if num_episode % 100 == 0:\n",
    "            loss = compute_td_loss(batch_size)\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "    if i % 100 == 0:\n",
    "        mean_rewards.append(np.mean(all_rewards[-100:]))\n",
    "        plot(i, mean_rewards, losses)\n",
    "        now = datetime.today().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        torch.save(model, \"../save/\"+now+\".pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
